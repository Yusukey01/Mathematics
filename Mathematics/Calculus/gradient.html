<!DOCTYPE html>
<html>
    <head> 
        <title>Gradient Descent</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Introduction to Optimization</h1>
        <blockquote>
            In machine learning, parameter estimation as known as <strong>model fitting</strong> requires solving 
            <strong>optimization problem</strong>:
            \[
            \theta^* \in \arg \min_{\theta \in \Theta} \mathcal{L}(\theta), \qquad \Theta \subset \mathbb{R}^d
            \]
            where \(\mathcal{L}(\theta)\) is a loss function(objective function),  \(\Theta\) is a parameter space, and 
            \(d\) is the number of variables being optimized over. 
            <br><br>
            Since finding a global optimum is too expensive or impossible in practice, our target will be a local optimum.
            <br>
            A point \(\theta^*\) is a local minimum if: 
            <br>
            \[
            \exists \, \delta > 0, \, \forall \, \theta \in \Theta \text{ such that } \| \theta - \theta^* \| < \delta, \, \mathcal{L}(\theta^*) \leq  \mathcal{L}(\theta).
            \]
            For a continuously twice differentiable function \(\mathcal{L}(\theta)\), to confirm that \(\theta^*\) is a local 
            minimum, following two conditions must be satisfied:
            <ol>
                <li>The <strong>gradient vector</strong> is equal to zero.</li>
                \[
                g(\theta^*) = \nabla \mathcal{L}(\theta^*) = 0
                \]
                <li>The <strong>Hessian matrix</strong> is positive definite.</li>
                \[
                H(\theta^*) = \nabla^2 \mathcal{L}(\theta^*) \succ 0
                \]
            </ol>
            <br>
            Often we need the <strong>feasible set</strong> \(\mathcal{C}\) as the subset of the parameter space \(\Theta\) that 
            satisfies a set of <strong>constraints</strong>:
            \[
            \mathcal{C} = \{\theta : g_j (\theta) \leq 0 : j \in \mathcal{I}, \, h_k (\theta) = 0 : k \in \mathcal{E}\} \subset \mathbb{R}^d
            \]
            where \(\mathcal{I}\) is a set of inequality constraints and \(\mathcal{E}\) is a set of equality constraints.
            <br><br>
            Usually, we convert the <strong>constrained optimization problem </strong> into an unconstrained one by introducing penalty 
            terms that measure how much we violate each constraint and adding them to the objective function. 
        </blockquote>

        <h1>Convexity</h1>
        <blockquote>
        Usually we design models so that their training objectives are <strong>convex</strong> because in the convex optimization problem, 
        every local minimum is actually a "global" minimum. 
        <br><br>
        A set \(\mathcal{S}\) is a convex if for any \(x, x' \in \mathcal{S}\), 
        \[
        \lambda x + (1 - \lambda) x' \in \mathcal{S}, \, \forall \lambda \in [0, 1].
        \]
        A function \(f(x)\) is said to be a <strong>convex function</strong> if it is defined on a convex set and if for any \(x, y \in \mathcal{S}\) and for any 
        \(0 \leq \lambda \leq 1\),
        \[
        f(\lambda x + (1 - \lambda)y) \leq \lambda f(x) + (1 - \lambda) f(y).
        \]
        For example, the cross-entropy loss function(See <a href="../Probability/entropy.html">Entropy</a>) is convex. 
        <div class="theorem">
            <span class="theorem-title">Theorem 1:</span>
            Suppose \(f: \mathbb{R}^n \to \mathbb{R}\) is \(C^2\). Then \(f\) is convex if and only if the Hessian matrix 
            \(H = \nabla^2 f(x)\) is positive semidefinite for all \(x \in dom(f)\). Also, \(f\) is strictly convex if \(H\) 
            is positive definite. 
        </div> 
        <div class="proof">
            <span class="proof-title">Proof:</span>
            Suppose for any \(x, y \in \mathbb{R}^n\) and \(\lambda \in (0, 1)\), we define  \(h: [0, 1] \to \mathbb{R}\) 
            as follows:
            \[
            h(\lambda) = f(\lambda a + (1-\lambda)b).
            \]
            For all \(z, w, p \in [0, 1]\), let \(\lambda = pz + (1-p)w\). Then
            \[
            h(\lambda) = f((pz + (1-p)w) a + (1-(pz + (1-p)w))b) \leq ph(z) + (1-p)h(w).
            \]
            Thus, \(h\) is a convex function. 
            <br>
            Rewriting \(h\), we have
            \[
            h(\lambda) = f(b + t(a-b)).
            \]
            Taking the second derivative with respect to \(t\), we obtain:
            \[
            \begin{align*}
            &\frac{dh}{dt} = (\nabla f(b + t(a - b)))^T (a - b) \\\\
            &\frac{d^2h}{dt^2} = (a - b)^T (\nabla^2 f(b + t(a - b))) (a - b)
            \end{align*}
            \]
            Here, \(\nabla^2 f(x)\) is the Hessian matrix of \(f\). 
            <br>
            For \(h\) to be a convex function, we must have:
            \[
            \frac{d^2h}{dt^2} \geq 0 \quad \forall t \in [0, 1].
            \]
            This implies the Hessian matrix is positive semidefinite for all \(x\).
            <br>
            For the sake of space, we omit the full proof.
        </div>
        </blockquote>

        <h1>Gradient Descent</h1>
        <blockquote>

        </blockquote>

        <h1>Stochastic Gradient Descent</h1>
        <blockquote>
        </blockquote>

        <h1>Sub-gradient Descent</h1>
        <blockquote>
        </blockquote>

        <a href="../../index.html">Back to Home </a>
        <br> <a href="calculus.html">Back to Calculus </a>

        
    </body>
</html>