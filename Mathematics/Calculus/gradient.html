<!DOCTYPE html>
<html>
    <head> 
        <title>Gradient Descent</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Introduction to Optimization</h1>
        <blockquote>
            In machine learning, parameter estimation as known as <strong>model fitting</strong> requires solving 
            <strong>optimization problem</strong>:
            \[
            \theta^* \in \arg \min_{\theta \in \Theta} \mathcal{L}(\theta), \qquad \Theta \subset \mathbb{R}^d
            \]
            where \(\mathcal{L}(\theta)\) is a loss function(objective function),  \(\Theta\) is a parameter space, and 
            \(d\) is the number of variables being optimized over. 
            <br><br>
            Since finding a global optimum is too expensive or impossible in practice, our target will be a local optimum.
            <br>
            A point \(\theta^*\) is a local minimum if: 
            <br>
            \[
            \exists \, \delta > 0, \, \forall \, \theta \in \Theta \text{ such that } \| \theta - \theta^* \| < \delta, \, \mathcal{L}(\theta^*) \leq  \mathcal{L}(\theta).
            \]
            For a continuously twice differentiable function \(\mathcal{L}(\theta)\), to confirm that \(\theta^*\) is a local 
            minimum, following two conditions must be satisfied:
            <ol>
                <li>The <strong>gradient vector</strong> is equal to zero.</li>
                \[
                g(\theta^*) = \nabla \mathcal{L}(\theta^*) = 0
                \]
                <li>The <strong>Hessian matrix</strong> is positive-definite.</li>
                \[
                H(\theta^*) = \nabla^2 \mathcal{L}(\theta^*) \succ 0
                \]
            </ol>
            <br>
            Often we need the <strong>feasible set</strong> \(\mathcal{C}\) as the subset of the parameter space \(\Theta\) that 
            satisfies a set of <strong>constraints</strong>:
            \[
            \mathcal{C} = \{\theta : g_j (\theta) \leq 0 : j \in \mathcal{I}, \, h_k (\theta) = 0 : k \in \mathcal{E}\} \subset \mathbb{R}^d
            \]
            where \(\mathcal{I}\) is a set of inequality constraints and \(\mathcal{E}\) is a set of equality constraints.
            <br><br>
            Usually, we convert the <strong>constrained optimization problem </strong> into an unconstrained one by introducing penalty 
            terms that measure how much we violate each constraint and adding them to the objective function. 
        </blockquote>

        <h1>Convexity</h1>
        <blockquote>

        </blockquote>

        <h1>Gradient Descent</h1>
        <blockquote>

        </blockquote>

        <h1>Stochastic Gradient Descent</h1>
        <blockquote>
        </blockquote>

        <h1>Sub-gradient Descent</h1>
        <blockquote>
        </blockquote>

        <a href="../../index.html">Back to Home </a>
        <br> <a href="calculus.html">Back to Calculus </a>

        
    </body>
</html>