<!DOCTYPE html>
<html>
    <head> 
        <title>Determinant</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </head>
    <body> 
        <h1>Determinants</h1>
        <blockquote>
        For \(n \geq 2\), the <strong>determinant</strong> of an \(n \times n\) matrix \(A\) is denined by 
        \[detA = \sum_{j=1}^n (-1)^{1+j} a_{1j} detA_{1j} 
               = a_{11}detA_{11}-a_{12}detA_{12}+\cdots+(-1)^{1+n}a_{1n}detA_{1n}
               = a_{11}C_{11}+a_{12}C_{12} + \cdots + c_{1n}C_{1n} 
        \]
        where \(C_{ij}=(-1)^{i+j} detA_{ij}\) is the \((i, j)\)-<strong>cofactor</strong> of \(A\). 
        <br><br>For example, consider the determinant of 
        \[
        A =
        \begin{bmatrix}
            3 & 2 & 5 \\
            7 & 5 & 4 \\
            0 & 1 & 0\\
        \end{bmatrix}
        \]
        then the determinant of \(A\) is 
        \[
        detA 
        = 3det\begin{bmatrix} 5 & 4 \\ 1 & 0\\ \end{bmatrix} 
          -2det\begin{bmatrix} 7 & 4 \\ 0 & 0\\ \end{bmatrix}
          +5det\begin{bmatrix} 7 & 5 \\ 0 & 1\\ \end{bmatrix}
        = 3(-4)-2(0)+5(7) = 23.
        \]
        <br>The <strong>cofactor expantion</strong> can be applied to any row or even column. If we choose a row that contains 
        many zeros, we can minimize our computation(but in general it is really expensive). the cofactor expansion across the third
        row of \(A\) is 
        \[
        detA 
        = 0 -1det\begin{bmatrix} 3 & 5 \\ 7 & 4\\ \end{bmatrix} + 0
        = -1(12-35) = 23
        \]
        or, for example, the cofactor expansion down the first "column" is 
        \[
        detA 
         = 3det\begin{bmatrix} 5 & 4 \\ 1 & 0\\ \end{bmatrix} 
            -7det\begin{bmatrix} 2 & 5 \\ 1 & 0\\ \end{bmatrix}
            +0det\begin{bmatrix} 2 & 5 \\ 5 & 4\\ \end{bmatrix}
         = 3(-4)-7(-5)+0 = 23.
        \]
        <br>These calculations imply that the determinant of a <strong>triangular matrix</strong> is just
        the product of diagonal entries. For example, 
        \[
        det\begin{bmatrix}
        1 & 7 & 5 & 4 & 2 \\
        0 & 2 & 9 & 2 & 3 \\
        0 & 0 & 3 & 5 & 7\\
        0 & 0 & 0 & 4 & 7\\
        0 & 0 & 0 & 0 & 5\\
        \end{bmatrix}
        = 1 \cdot 2 \cdot 3 \cdot 4 \cdot 5 = 120.
        \]
        In addition, you might immediately notice that the <strong>transpose</strong> of this 
        upper triangular matrix has the same determinant because the resulting matrix is a lower triangular matrix and
        the diagonal entries are not changed by the transpose operation. Actually, this is not only for triangular matrices. 
        In general, if a matrix is square, \(detA = detA^T\). Take a look at our matrix \(A\) again. 
        \[
        A^T =
        \begin{bmatrix}
            3 & 7 & 0 \\
            2 & 5 & 1 \\
            5 & 4 & 0\\
        \end{bmatrix}
        \qquad
        detA^T
        = 3det\begin{bmatrix} 5 & 1 \\ 4 & 0\\ \end{bmatrix} 
            -7det\begin{bmatrix} 2 & 1 \\ 5 & 0\\ \end{bmatrix}
            +0det\begin{bmatrix} 2 & 5 \\ 5 & 4\\ \end{bmatrix}
        = 3(-4) -7(-5)+0 = 23 = detA.
        \]
        <br>The cofactor of \(a_{1j}\) in \(A\) is equal to the cofactor of \(a_{j1}\) in \(A^T\), so 
        the cofactor expansion across the first row of \(A\) is the same as the cofactor expansion down the 
        first column of \(A^T\). This relationship is true for all rows of any square matrix. 
        <br><br>
        Determinants are <strong>multiplicative</strong>. For example, let 
        \[
        A = \begin{bmatrix}
        1 & 2  \\
        8 & 9  \\
        \end{bmatrix},
        \qquad 
        B = \begin{bmatrix}
        5 & 7  \\
        4 & 6  \\
        \end{bmatrix}, 
        \qquad
        AB = \begin{bmatrix}
        13 & 19  \\
        76 & 110  \\
        \end{bmatrix}
        \]
        then
        \[detA = 9-16=-7, \qquad detB = 30-28 =2, \qquad detAB = 1430-1444=-14 = (detA)(detB).\]
        Note: \(det(A+B) \neq detA + detB\).

        <br><br>
        Here, determinants with elementary row operations.
        \[
        det\begin{bmatrix}
        a & b  \\
        c & d  \\
        \end{bmatrix}
        = ad-bc
        \qquad 
        det\begin{bmatrix}
        c & d  \\
        a & b  \\
        \end{bmatrix}
        = cb-ad=-(ad-bc) 
        \qquad
        det\begin{bmatrix}
        a & b  \\
        kc & kd  \\
        \end{bmatrix}
        = kad-kbc = k(ad-bc)
        \qquad
        det\begin{bmatrix}
        a & b  \\
        c+2k & d+2k  \\
        \end{bmatrix}
        = a(d+2k)-b(c+2k) = ad-bc
        \]
        </blockquote>

        <h1>Cramer's Rule</h1>
        <blockquote>
        Let \(A\) be an invertible \(n \times n\) matrix. \(\forall b \in \mathbb{R}^n \), \(Ax = b\) has
        a solution \(x\) whose entries given by
        \[x_i = \frac{detA_i(b)}{detA}, \qquad i = 1, 2, \cdots, n    \tag{1}\]
        where \(A_i(b)\) is the matrix obtained from \(A\) replacing the \(i\)th column by \(b\).
        <br><br>
        The outline of proof is as bellow. 
        \[
        AI_i(x)= 
        \begin{bmatrix}
        Ae_1 & Ae_2 & \cdots & Ax & \cdots & Ae_n  \\
        \end{bmatrix}
        =
        \begin{bmatrix}
        a_1 & a_2 & \cdots & b & \cdots & a_n  \\
        \end{bmatrix}
        = A_i(b)
        \]
        Then by the multiplicative property of determinants, 
        \[(detA)(detI_i(x))=detA_i(b) \Longrightarrow (detA)x_i = detA_i(b)\]
        and since \(A\) is invertible, \(detA \neq 0\), we get (1).
        <br><br>
        Additional info: <strong>Laplace transforms</strong> convert some system of linear differential equations into a system of
        linear algebraic equations (A: coefficients with parameter s,  x: functions, b: initial conditions). Then, 
        Cramer's rule could solve the system. 
        </blockquote>

        <h1>Inverse Formula</h1>
        <blockquote>
        The Cramer's rule gives us the general inverse formula. However, both inverse formula and Cramer's rule are useful mainly
        theoritical discussions. 
        <br><br>
        Let \(A\) be an invertible matrix. then 
        \[A^{-1} = \frac{1}{detA}adjA\]
        where \(adjA\) is the <strong>adjugate</strong> of \(A\), which is the matrix of cofactors of \(A\).
        <br><br>
        For example, let a matrix A = 
        \begin{bmatrix}
        -1 & 2 & 3 \\
         2 & 1 & -4 \\
         3 & 3 & 2 \\
        \end{bmatrix}
        To get \(adjA\), we need the nine cofactors of \(A\): 
        \[C_{11}=+(2+12)=14,\qquad C_{21}=-(4-9)=5, \qquad C_{31}=+(-8-3)=-11\]
        \[C_{12}=-(4+12)=-16,\qquad C_{22}=+(-2-9)=-11, \qquad C_{32}=-(4-6)=2\]
        \[C_{13}=+(6-3)=3, \qquad C_{23}=-(-3-6)=9, \qquad C_{33}=+(-1-4)=-5\]
        and \(detA = -1(2+12)-2(4+12)+3(6-3)=-14-32+9=-37\).
        Note that we can double check if \(detA\) is correct or not by 
        \[(adjA)A = 
        \begin{bmatrix}
        14 & 5 & -11 \\
        -16 & -11 & 2 \\
        3 & 9 & -5 \\
        \end{bmatrix}
        \begin{bmatrix}
        -1 & 2 & 3 \\
         2 & 1 & -4 \\
         3 & 3 & 2 \\
        \end{bmatrix}
        =-37I
        \]
        Thus, \(detA = -37\), and 
        \(A^{-1}
        = 
        \begin{bmatrix}
        \frac{-14}{37} & \frac{-5}{37} & \frac{11}{37} \\
        \frac{16}{37} & \frac{11}{37} & \frac{-2}{37} \\
        \frac{-3}{37} & \frac{-9}{37} & \frac{5}{37} \\
        \end{bmatrix}.
        \)
        </blockquote>

        <h1>Invertible Matrix Theorem</h1>
        We have seen many properties of invertible matrices. It's good time to summarize the properties. We will see more later. 
        <br><br>
        \(\textbf{Theorem} \qquad\)
        <br>
        Let \(A\) be an \(n \times n\) matrix , then the following statemets are logically equivalent. 
        <blockquote>
            <ol>
                <li>\(A\) is invertible.</li>
                <li>There is an \(n \times n\) matrix \(B\) s.t. \(AB = I\) and \(BA = I\).</li>
                <li>\(Ax = 0\) has only trivial solution.</li>
                <li>\(A\) has \(n\) pivot positions.</li>
                <li>\(A\) is row equivalent to \(I_n\).</li>
                <li>\(\forall b \in \mathbb{R}^n , Ax = b\) has at least one solution.</li>
                <li>The column of \(A\) span \(\mathbb{R}^n\).</li>
                <li>The linear transformation \(x \mapsto Ax\) maps \(\mathbb{R}^n\) onto \(\mathbb{R}^n\).</li>
                <li>The columns of \(A\) form a linearly independent set.</li>
                <li>The linear transformation \(x \mapsto Ax\) is one-to-one.</li>
                <li>\(A^T\) is invertible.</li>
                <li>\(detA \neq 0\).</li>
                <li></li>
            </ol>
        </blockquote>

        <blockquote>

        </blockquote>


        <a href="index.html">Back to Home </a>
        <br> <a href="linear_algebra.html">Back to Linear Algebra </a>
    </body>
</html>