<!DOCTYPE html>
<html>
    <head> 
        <title>Orthogonality</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Derivative of the Frobenius norm</h1>
        <blockquote>
            Derivatives implicitly rely on <strong>norms</strong> to measure the magnitude of changes in both the input \(dx\) 
            and the output \(df\) ensuring a consistent comparison of their scales.
            <br><br>
            Recall, the <strong>Frobenius norm</strong> of a matrix \(X \in \mathbb{R}^{m \times n}\) is defined as:
            \[
             f(X) = \| X \|_F = \sqrt{\text{tr }(X^TX)} 
            \] 
            (See <a href="../Linear_algebra/trace.html">Section I - Part 10</a>)
            <br>
            Now, taking the differential \(df\):
            <br><br>
            First, by the chain rule:
            \[
            df = \frac{1}{2\sqrt{\text{tr }(X^TX)}}d[\text{tr }(X^TX)]
            \]
            Note: for any matrix \(A\),
            \[
            \begin{align*}
            d(\text{tr }(A)) &= \text{tr }(A + dA) - \text{tr }(A) \\\\\
                             &= \text{tr }(A) + \text{tr }(dA) - \text{tr }(A) \\\\
                             &= \text{tr }(dA)
            \end{align*}
            \]
            Thus:
            \[
            df = \frac{1}{2\sqrt{\text{tr }(X^TX)}}\text{tr }[d(X^TX)]
            \]
            By the product rule:
            \[
            \begin{align*}
            df &= \frac{1}{2\sqrt{\text{tr }(X^TX)}}\text{tr }[dX^TX + X^TdX]\\\\
               &= \frac{1}{2\sqrt{\text{tr }(X^TX)}}\text{tr }(dX^TX) + \text{tr }(X^TdX)
            \end{align*}
            \]
            Since \(\text{tr }(dX^TX)  = \text{tr }((dX^TX)^T) = \text{tr }(X^TdX)\),
            \[ 
            \begin{align*}
              df &= \frac{1}{2\sqrt{\text{tr }(X^TX)}}2\text{tr }(X^TdX)\\\\
                 &= \frac{1}{\sqrt{\text{tr }(X^TX)}}\text{tr }(X^TdX)
            \end{align*}
            \]
            Here, \(\text{tr }(X^TdX)\) represents the <strong>Frobenius inner product</strong> of \(X\) and \(dX\). Then:
            \[
            df = \left\langle \frac{X}{\sqrt{\text{tr }(X^TX)}}, dX \right\rangle_F  \tag{1}
            \]
            Therefore, 
            \[
            \nabla f = \frac{X}{ \| X \|_F}.
            \]
            <br>
            Note:The expression in (1) is equivalent to
            \[
            df = \text{tr }((\nabla f)^TdX) \tag{2}
            \]
            <br>
            The trace operator satisfies linearity and the cyclic property, making it a convenient way to express derivatives 
            in terms of gradients.
            <br>
            For example, consider \(f(A) = x^TAy\) where \(A\) is 
            a \(m \times n\) matrix, \(x \in \mathbb{R}^m\), and  \(y \in \mathbb{R}^n\).
            <br>
            By the product rule,
            \[
            df = x^TdAy
            \]
            Since \(df\) is a scalar,  taking the trace does not change its value:
            \[
            df = \text{tr }(x^TdAy)
            \]
            By the cyclic property of the trace:
            \[
            df = \text{tr }(yx^TdA)
            \]
            Therefore, comparing this with \(df = \text{tr }((\nabla f)^TdA)\), 
            \[
            \nabla f = (yx^T)^T = xy^T
            \]
        </blockquote>

        <h1>Derivative of the Determinant</h1>
        <blockquote>
            The derivative of the determinant of a square matrix \(A \in \mathbb{R}^{n \times n}\) an be expressed 
            using several equivalent forms.  
            <br>
            Recall: 
            \[
            \text{adj }(A) = \text{cofactor }(A)^T = (\det A)A^{-1}.
            \]
            (See <a href="../Linear_algebra/determinants.html">Section I - Part 4</a>)
            This implies:
            \[
            \text{cofactor }(A) = \text{adj }(A)^T = (\det A)(A^{-1})^T.
            \]
            <br><br>
            By the cofactor expansion of the determinant based on \(i\)-th row of \(A\):
            \[
            \det (A) = A_{i1}C_{i1} + A_{i2}C_{i2} +  \cdots + A_{in}C_{in}
            \]
            Thus, \(\frac{\partial \det A}{\partial A_{ij}} = C_{ij} \) and then:
            \[
            \nabla (\det A) = \text{cofactor } (A)
            \]
            Equivalently, using the expression (2): 
            \[
            \begin{align*}
            df &= \text{tr }(\text{cofactor }(A)^T dA) \\\\
               &= \text{tr }(\text{adj }(A) dA) \\\\
               &= \text{tr }((\det A)A^{-1} dA)
            \end{align*}
            \]
            Therefore,
            \[
            \nabla (\det A) = \text{cofactor } (A) = \text{adj }(A)^T = (\det A)(A^{-1})^T
            \]


        </blockquote>
        <a href="../index.html">Back to Home </a>
        <br> <a href="calculus.html">Back to Calculus </a>
    </body>
</html>