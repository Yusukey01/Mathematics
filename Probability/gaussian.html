<!DOCTYPE html>
<html>
    <head> 
        <title>Gaussian Distribution</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Gaussian Function</h1>
        <blockquote>
        </blockquote>

        <h1>Normal Distribution</h1>
        <blockquote>
            A random variable \(X\) has a <strong>normal(Gaussian) distribution</strong> with parameters \(\mu \) and 
            \(\sigma^2\) if its p.d.f. is given by 
            \[
            f(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{\frac{-(x - \mu)^2}{2\sigma^2}}  \qquad x \in \mathbb{R}
            \]
            where \(\mu \in (-\infty, \infty)\) and \(\sigma > 0\) and it is denoted as \(X \sim N(\mu,  \sigma^2)\).
            <br><br>
            <div style="text-align: center;">
                <img src="normal_dist_pdf.png" alt="Normal Distribution PDF" style="width:600px;">
            </div>
            <br>
            The above figure shows the normal p.d.f. curve. \(\mu\) is the center, and \(\sigma\) is the distance from 
            the center to the inflection point of the curve. The one reason the normal distribution is widely used in statistics 
            and machine learning as well, the parameters capture its mean and variance, which are essential properties of the distribution. 
            \[
            \mathbb{E }[X] = \mu \qquad \text{Ver }(X) = \sigma^2.
            \]
            <br>
            The simplest and useful normal distribution is the one with zero mean and unit variance. We call it 
            the <strong>standard normal distribution</strong> denoted by
            \[
            Z \sim N(0, 1).
            \]
            Any normally distributed random variable can be "transformed" to a standard normal random variable. If 
            \(X \sim N(\mu,  \sigma^2)\), then 
            \[
            Z = \frac{X- \mu}{\sigma}\sim N(0, 1).
            \]
            This process is called <strong>standardization</strong>. This is just a special case of the linear transformation:
            \[
            Y = aX + b \sim N(a\mu+b, a^2\sigma^2)
            \]
            Here, \(a = \frac{1}{\sigma} \) and \(b = \frac{-\mu}{\sigma}\) and then you 
            get \(\mathbb{E}[\frac{1}{\sigma}x -\frac{\mu}{\sigma}] = 0 \) and \(\text{Var }(\frac{1}{\sigma}x -\frac{\mu}{\sigma}) =1\).
            <br><br>
            The p.d.f. of \(Z\) is denoted by 
            \[
            \phi (z) = f(x) = \frac{1}{\sqrt{2\pi}}e^{\frac{-z^2}{2}} \qquad z \in \mathbb{R}
            \]
            and c.d.f. of \(Z\) is denoted by 
            \[
            \Phi (z) = P(Z \leq z) = \int_{-\infty} ^z \phi (u)du.
            \]
        </blockquote>

        <h1>Central Limit Theorem</h1>
        <blockquote>
            Now, we consider a set of random variables \(\{X_1, X_2, \cdots, X_n\}\). We assume in <strong>random sampling</strong>, each 
            \(X_i\) has the same distribution and is independent of each other. We call it <strong>independent and identically distributed(i.i.d.)</strong>. 
            In this case, a <strong>sample mean</strong>: \(\frac{1}{n}\sum_{i=1} ^n X_i\) is not exactly equivalent to the <strong>population mean</strong>: \(\mu\) 
            because there are many different sampling possibilities. However, the "average" of sample means is equal to \(\mu\).
            \[
            \begin{align*}
            \mathbb{E}[\bar{X}] &=  \mathbb{E}[\frac{1}{n}(X_1 + X_2 + \cdots +X_n)] \\\\
                                &= \frac{1}{n}[\mathbb{E}[X_1] + \mathbb{E}[X_2] + \cdots + \mathbb{E}[X_n]] \\\\
                                &= \frac{n\mu}{n} \\\\
                                &= \mu
            \end{align*}
            \]
            <div class="theorem">
                <span class="theorem-title">Theorem 1: Central Limit Thorem</span>
                Let \(X_1, X_2, \cdots, X_n\) be i.i.d. random variables with mean \(\mu\) and variance \(\sigma^2\). Then the distribution of 
                \[
                Z = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}}
                \] 
                converges to the standard normal distribution as the smaple size \(n \to \infty\).
            </div>
            If the smaple size \(n\) is large enough,
            \[
            \bar{x} \sim N(\mu, \frac{\sigma^2}{n})
            \]
            and also, 
            \[
            \sum_{i =1} ^n  x_i \sim N(n\mu , n\sigma^2).
            \]
            This theorem is another reason the normal distribution is widely used in practice. 
        </blockquote>
        <a href="../index.html">Back to Home </a>
    <br> <a href="probability.html">Back to Probability </a>   
</body>
</html>