<!DOCTYPE html>
<html>
    <head> 
        <title>Matrix Algebra</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </head>
    <body> 
        <h1>Diagonal Matrix</h1>
        <blockquote>
            A <strong>diagonal matrix</strong> is \(n \times n\) square matrix whose entries outside the <strong>main diagonal</strong> are all zero.
            \[
            AB = 
            \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6 \\
            7 & 8 & 9\\
            \end{bmatrix}
            \begin{bmatrix}
            2 & 0 & 0 \\
            0 & 3 & 0 \\
            0 & 0\ & 4\
            \end{bmatrix}
            =
            \begin{bmatrix}
            2 & 6 & 12 \\
            8 & 15 & 24 \\
            14 & 24 & 36\\
            \end{bmatrix}
            \]

            \[
            BA =
            \begin{bmatrix}
            2 & 0 & 0 \\
            0 & 3 & 0 \\
            0 & 0\ & 4\
            \end{bmatrix}
            \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6 \\
            7 & 8 & 9\\
            \end{bmatrix}
            =
            \begin{bmatrix}
            2 & 4 & 6 \\
            12 & 15 & 18 \\
            28 & 32 & 36\\
            \end{bmatrix}
            \]
            As you can see the right multiplication by the diagonal matirx \(B\) is the product of each "column" of
            \(A\) and its corresponding diagonal entry of \(B\) and on the other hand, the left multiplication 
            by \(B\) affects each "row" of \(A\).
            <br><br> 
            A diagonal matrix with 1's on the main diagonal is called an <strong>identity matrix</strong> denoted by \(I_n\). 
            Like the above example, \(AB \neq BA\) in general, but clearly \(AI = IA\) and the resulting matix is just the original \(A\). 
            For example, 
            \[
            AI = 
            \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6 \\
            7 & 8 & 9\\
            \end{bmatrix}
            \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 1 & 0 \\
            0 & 0\ & 1\
            \end{bmatrix}
            =
            \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 1 & 0 \\
            0 & 0\ & 1\
            \end{bmatrix}
            \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6 \\
            7 & 8 & 9\\
            \end{bmatrix}
            =
            \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6 \\
            7 & 8 & 9\\
            \end{bmatrix}.
            \]
        </blockquote>

        <h1>Transpose</h1>
        <blockquote>
        The <strong>transpose</strong> of an \(m \times n\) matrix \(A\) is the \(n \times m\) matrix 
        interchanging its rows into the corresponding columns, and denoted by \(A^T\). 
        \[
        A = 
        \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6 \\
            7 & 8 & 9\\
        \end{bmatrix}
        \qquad
        A^T = 
        \begin{bmatrix}
        1 & 4 & 7 \\
        2 & 5 & 8 \\
        3 & 6 & 9\\
        \end{bmatrix}
        \]
        Note that the transpose operation does not change the main diagonal entries. 
        There are many proparties related to the transpose operation. Let me introduce some of them.
          
        <blockquote>
        <ol>
            <li>\((A^T)^T = A\)</li>
            <li>\((A+B)^T = A^T + B^T\)</li>
            <li>\((AB)^T  = B^TA^T\)</li>
        </ol>
        </blockquote>
        For (3), in general we can say as follows.
        \[
            \begin{aligned}
            \textbf{Theorem 1} \quad  
            & \text{The transpose of a product of matrices is equal to the product of their transposes in the reverse order.}
            \end{aligned}
        \] 
        <br> 
        Let \(n\) be the number of columns of \(A\) (= the number of rows of \(B\)). Then, 
        \[((AB)^T)_{ij} = (AB)_{ji} =\sum_{k=1}^n a_{jk}b_{ki}.\]
        Also, 
        \[(B^TA^T)_{ij} = \sum_{k=1}^n b_{ki}a_{jk} = \sum_{k=1}^n a_{jk}b_{ki}.\]  
        This is also true for the product of more than two matrices.
        

        </blockquote>

        <h1>Inverse</h1>
        <blockquote>
        An \(n \times n\) matrix \(A\) is <strong>invertible</strong> if there is an \(n \times n\) matrix \(B\)
        such that \[AB = BA = I.\]
        The matrix \(B\) is the inverse of \(A\) denoted by \(A^{-1}\). Also, a matrix that is NOT invertible is 
        called a <strong>singular matrix</strong>. 

        <br><br>By the definition, we can say that \((A^{-1})^{-1} = A\) and also \((AB)^{-1} = B^{-1}A^{-1}\) because 
        \[(AB)(B^{-1}A^{-1}) = A(BB^{-1})A^{-1} = AIA^{-1} = AA^{-1} = I.\]
        <br>

        Since we learned the transpose of a matrix, we get the follwing theorem.
        \[
            \begin{aligned}
            \textbf{Theorem 2} \quad  
            & \text{If} A \text{ is invertible, then so is } A^T and (A^T)^{-1} = (A^{-1})^T.
            \end{aligned}
        \]
        
        Suppose a matrix \(A\) is an invertible matrix. By the Theorem 1, 
        \[(A^{-1})^TA^T = (AA^{-1})^T = I^T = I\]
        and similarly, 
        \[A^T(A^{-1})^T = (A^{-1}A)^T = I^T = I.\]
        Thus, \(A^T\) is an invertible matrix and its inverse is \((A^{-1})^T\).
        
        <br><br>
        There is a simple formula for the inverse of a \(2 \times 2\) matrix.
        Let \(A = 
        \begin{bmatrix}
        a & b \\
        c & d \\
        \end{bmatrix}\). If the <strong>determinant</strong> of \(A\), \(det A = ad - bc\) is nonzero, then \(A\) is
        invertible and 
        \[A^{-1} = \frac{1}{detA}
        \begin{bmatrix}
        d & -b \\
        -c & a \\
        \end{bmatrix}
        \]
        So, \(detA = 0\) implies the matrix \(A\) is not invertible. 
        <br>For example, 
        \[
        \begin{bmatrix}
        1 & 9 \\
        8 & 2 \\
        \end{bmatrix}
        \frac{1}{(2 - 72)}
        \begin{bmatrix}
        2 & -9 \\
        -8 & 1 \\
        \end{bmatrix}
        =
        \begin{bmatrix}
        1 & 9 \\
        8 & 2 \\
        \end{bmatrix}
        \begin{bmatrix}
        -\frac{1}{35} & \frac{9}{70} \\
        \frac{4}{35} & -\frac{1}{70} \\
        \end{bmatrix}
        =
        \begin{bmatrix}
        1 & 0 \\
        0 & 1 \\
        \end{bmatrix}
        \]
        <br>
        Now we can solve the matrix equation \(Ax = b\) for the vector \(x\) by using inverse. 
        \[Ax=b  \Rightarrow  A^{-1}Ax= A^{-1}b  \Rightarrow  Ix = A^{-1}b \Rightarrow x = A^{-1}b\]
        <br>
        Note: In practice, solving by row reduction is faster than finding \(A^{-1}\) and can be more accurate.
        </blockquote>

        <h1>Elementary Matrices</h1>
        <blockquote>
        An <strong>elemetary matrix</strong> stores a single elemetary row opelation into an identity matrix. 
        <br>
        For example, given
        \[
        A = 
        \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6 \\
            7 & 8 & 9\\
        \end{bmatrix}
        \qquad
        E_1 = 
        \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 0 & 1\\
            0 & 1 & 0\\
        \end{bmatrix} 
        \qquad
        E_2 = 
        \begin{bmatrix}
            2 & 0 & 0 \\
            0 & 1 & 0 \\
            0 & 0 & 1\\
        \end{bmatrix}
        \qquad
        E_3 = 
        \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 1 & 0 \\
            0 & -3 & 1\\
        \end{bmatrix}
        \] 
        Then, 
        \[
        E_1A = 
        \begin{bmatrix}
            1 & 2 & 3 \\
            7 & 8 & 9 \\
            4 & 5 & 6\\
        \end{bmatrix}
        \qquad
        E_2A = 
        \begin{bmatrix}
            2 & 4 & 6 \\
            4 & 5 & 6\\
            7 & 8 & 9\\
        \end{bmatrix}
        \qquad
        E_3A = 
        \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6\\
            -5 & -7 & -9\\
        \end{bmatrix}
        \] 
        As you can see, \(E_1\) is interchanging Row 2 and Row 3, \(E_2\) is scaling Row 1 by 2,
         and \(E_3\) is adding (Row2 \(\times-3\)) to Row3. Moreover, we can store a "sequene" of the 
        row operations into a single matrix. 
        \[
        E_3E_2E_1A = 
        \begin{bmatrix}
        2 & 0 & 0 \\
        0 & 0 & 1\\
        0 & 1 & -3\\
        \end{bmatrix}
        \begin{bmatrix}
        1 & 2 & 3 \\
        4 & 5 & 6\\
        7 & 8 & 9\\
        \end{bmatrix}
        =
        \begin{bmatrix}
        2 & 4 & 6 \\
        7 & 8 & 9\\
        -17 & -19 & -21\\
        \end{bmatrix}
        = B
        \]
        Since elementary row operations are "reversible", there always exsits a corresponding inverse matrix. Thus, 
        using the inverse matrices and the resulting matrix \(B\), we can regenerate the original mmatrix \(A\). 
        \[
        (E_1^{-1}E_2^{-1}E_3^{-1})E_3E_2E_1A = (E_1^{-1}E_2^{-1}E_3^{-1})B
        \]
        \[
        A = 
        \begin{bmatrix}
        0.5 & 0 & 0 \\
        0 & 3 & 1\\
        0 & 1 & 0\\
        \end{bmatrix}
        \begin{bmatrix}
        2 & 4 & 6 \\
        7 & 8 & 9\\
        -17 & -19 & -21\\
        \end{bmatrix}
        = 
        \begin{bmatrix}
        1 & 2 & 3 \\
        4 & 5 & 6\\
        7 & 8 & 9\\
        \end{bmatrix}
        \] 
        <br>
        Although our matix \(A\) is not invertible in this case, above operations lead to an idea for finding \(A^{-1}\).
        If an \(n \times n\) matrix \(A\) is invertible, the reduced echelon form of the matrix must be \(I_n\). Then,
        each step of the row reduction will be described by an elementary matrix. 
        \[(E_k \cdots E_1)A = I_n\]
        \[A = (E_k \cdots E_1)^{-1}I_n = (E_k \cdots E_1)^{-1}\]
        \[A^{-1} = ((E_k \cdots E_1)^{-1})^{-1} = E_k \cdots E_1 = (E_k \cdots E_1 )I_n\]
        Therefore, the row reduction of the augmented matrix \(\begin{bmatrix} A & I \end{bmatrix}\)
        gives us \(\begin{bmatrix} I & A^{-1} \end{bmatrix}\) if \(A\) is invertible. 

        </blockquote>


        <h1>Partitions</h1>
        <blockquote>
            
        </blockquote>

        <h1>LU Factorization</h1>
        <blockquote>
            
        </blockquote>



    </body>
</html>