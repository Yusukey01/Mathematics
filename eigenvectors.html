<!DOCTYPE html>
<html>
    <head> 
        <title>Eigenvectors</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </head>
    <body> 
        <h1>Eigenvectors and Eigenvalues</h1>
        <blockquote>
            An <strong>eigenvector</strong> of an \(n \times n\) matrix \(A\) is a "nonzero" vector \(x\) s.t.
            \[Ax = \lambda x \tag{1}\]
            for some scalar \(\lambda\) that is called an <strong>eigenvalue</strong> of \(A\) if there is a
            nontrivial solution \(x\) of (1). We call such an \(x\) an eigenvector corresponding to \(\lambda\).
            Also, (1) gives us
            \[(A - \lambda I)x = 0 \tag{2}\] 
            \(\lambda\) is an eigenvalue of \(A\) iff (2) has a nontrivial solution, then set of all solutions of
            (2) is the \(Nul (A - \lambda I) \subseteq \mathbb{R}^n\) and is called the <strong>eigenspace</strong> of \(A\)
            corresponding to the eigenvalue \(\lambda\).
            <br><br>
            <blockquote>
                \(\textbf{Theorem 1}\)<br>
                The eigenvalues of a triangular matrix are the its main diagonal entries. 
            </blockquote><br>
                Suppose \(A \in \mathbb{R}^{3 \times 3} \) is a lower triangular matix and \(\lambda\) is an
                eigenvalue of \(A\). Then, 
                \[A - \lambda I = \begin{bmatrix} 
                  a_{11} - \lambda & 0 & 0 \\ 
                  a_{21} & a_{22} - \lambda & 0 \\
                  a_{31} & a_{32} & a_{33} - \lambda \\
                  \end{bmatrix}
                \]
                Since \(\lambda\) is an eigenvalue of \(A\), \((A-\lambda I)x =0\) has a nontrivial solution. In other words,
                the equation has a free variable. In this case, it will happen iff at least one of the main diagonal entries is zero
                so that \(\lambda\) is equal to one of the main diagonal entries of \(A\). Similarly, this is true for the upper triangular case
                and any higher dimensional cases. 
                <br><br>
                For example, 
                \[A = \begin{bmatrix} 0 & 1 & 8 \\  0 & 2 & 7 \\ 0 & 0 & 3 \\ \end{bmatrix}\]
                has eigenvalues; 0, 2, and 3. Since \(A\) has a zero eigenvalue, the equation (1) becomes
                homogeneous equation \(Ax =0\), which must have a nontrivil solution and it happens iff 
                <strong>\(A\) is a singular matrix(NOT invertible).</strong> We can double check it by computing
                \(det A = 0(6-0)-(0-0)+8(0-0)=0\). Since \(detA=0\), clearly, \(A\) is not invertible.
                <br><br>
                <blockquote>
                    \(\textbf{Theorem 2}\)<br>
                    If 
                </blockquote><br>


        </blockquote>

        <h1>X</h1>
        <blockquote>
        </blockquote>

        <h1>X</h1>
        <blockquote>
        </blockquote>

        <h1>X</h1>
        <blockquote>
        </blockquote>

        <h1>X</h1>
        <blockquote>
        </blockquote>

        <a href="index.html">Back to Home </a>
        <br> <a href="linear_algebra.html">Back to Linear Algebra </a>
    </body>
</html>