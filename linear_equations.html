<!DOCTYPE html>
<html>
    <head> 
        <title>Linear Equations</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </head>
    <body> 
        <h1>System of Linear Equations</h1>
        <blockquote>
            A <strong>linear equation</strong> can be written in the form 
            <strong>\[a_1x_1 + a_2x_2 + \cdots + a_nx_n = b\] </strong>
            where \(x_1 \cdots x_n \) are variables and \(b\) and the coefficients \(a_1 \cdots a_n\) are real or complex numbers.
            The index \(n\) would be more than thousands or millions in practice. 
            <br> We call a collection of linear equations including the same variables a <strong>system of linear equations</strong>, which 
            is said to be consistent if it has either <strong>exactly one solution</strong> or <strong>infinitely many solutions</strong>. 
            Finally, it is possible that a system of linear equations has <strong>no solution</strong> (the system is inconsistent).
            <br><br>
            Now, We would like to store "information" of a system(=What are the values of each coefficient?, How many equations?, How many variables?) 
            into a rectangular array called a <strong>matrix</strong>.
            <br>For example, the linear system 
            \[
            \begin{align}
             x_1\phantom{+a_20x_2}-3x_3 + \phantom{0}x_4 &= 10 \\
            4x_1 -5x_2 + 6x_3 -2x_4 &= -8 \\
            \phantom{a_3x_1+} 2x_2 + 2x_3 +5x_4 &=6
            \end{align}
            \]
            can be written as the <strong>coefficient matrix</strong> of the system 
            \[
            \begin{bmatrix}
            1 & 0 & -3  & 1\\
            4 & -5 & 6  & -2\\
            0 & 2 & 2  & 5
            \end{bmatrix}
            \] (This is a \(3 \times 4\) (read"3 by 4") matrix. The number of rows(=3) always comes first.)
            or 
            <br> can be witten as the <strong>augmented matrix</strong> of the system
            \[
            \begin{bmatrix}
            1 & 0 & -3 & 1 & 10\\
            4 & -5 & 6 & -2 & -8\\
            0 & 2 & 2 &  5 & 6\\
            \end{bmatrix}
            \]
            (This is a \(3 \times 5\) matrix includes the constants from the right sides of the equations. The number of rows = 3, and the number of columns = 5).
            <br><br>
            How can we solve the linear system? The key idea is to replace the system with an equivalent system
            which is easier to solve than the original. What does "equivalent" mean here? There are three elementary row operations. 
            If there is a sequence of the operations that transforms a matrix into other matrix, the two matrices are called 
            <strong>row equivalent</strong>.  The elementary row operations are as follows.
            <blockquote>
            <ol>
                <li>Replace one row by the sum of itself and a multiple of another row.(Replacement)</li>
                <li>Interchange two rows.(Interchange)</li>
                <li>Multiply all entries in a row by a nonzero constant.(Scaling)</li>
            </ol>
            </blockquote>
            <br>Let's solve our matrix by using these rules. First, we wnat to transform the matrix 
            into <strong>row echelon form</strong>, which satisfies following conditions: 
            <blockquote>
                <ol>
                    <li>All nonzero rows are above any rows of all zeros.</li>
                    <li>The first nonzero entry in each row appears further to the right than the first nonzero 
                        entry in the row directly above it.</li>
                    <li>All entries in a column below a leading entry are zero.</li>
                </ol>
                </blockquote>
            \[
            \begin{bmatrix}
            1 & 0 & -3 & 1 & 10\\
            4 & -5 & 6 & -2 & -8\\
            0 & 2 & 2 &  5 & 6\\
            \end{bmatrix}
            \xrightarrow{\text{Row2 $\leftrightarrow$ (Row2 - 4*Row1)}} 
            \begin{bmatrix}
            1 & 0 & -3 & 1 & 10\\
            0 & -5 & 18 & -6 & -48\\
            0 & 2 & 2 &  5 & 6\\
            \end{bmatrix}
            \xrightarrow{\text{Row3 $\leftrightarrow$ (Row3 + 2/5 * Row2)}} 
            \begin{bmatrix}
            1 & 0 & -3 & 1 & 10\\
            0 & -5 & -18 & -6 & -48\\
            0 & 0 & \frac{46}{5} & \frac{13}{5} & \frac{-66}{5}\\
            \end{bmatrix} \\ 
            \]
            <br>Next, we transform this matrix into <strong>reduced row echelon form(RREF)</strong>. A matrix in echelon form is RREF
            if the leading entry in each nonzero row is 1 and each leading 1 is the only nonzero entry in its column. 
            <br>
            \[
            \xrightarrow{\text{Row2 $\leftrightarrow$ (Row2 / -5)}}
            \begin{bmatrix}
            1 & 0 & -3 & 1 & 10\\
            0 & 1 & \frac{-18}{5} & \frac{6}{5} & \frac{48}{5}\\
            0 & 0 & \frac{46}{5} & \frac{13}{5}& \frac{-66}{5}\\
            \end{bmatrix} \\ 
            \xrightarrow{\text{Row3 $\leftrightarrow$ (Row3 * 5/46)}}
            \begin{bmatrix}
            1 & 0 & -3 & 1 & 10\\
            0 & 1 & \frac{-18}{5} & \frac{6}{5} & \frac{48}{5}\\
            0 & 0 & 1 & \frac{13}{46}& \frac{-33}{23}\\
            \end{bmatrix} \\ 
            \xrightarrow{\text{Row1 $\leftrightarrow$ (Row1 + 3*Row3)}}
            \begin{bmatrix}
            1 & 0 & 0 & \frac{85}{46} & \frac{131}{23}\\
            0 & 1 & \frac{-18}{5} & \frac{6}{5} & \frac{48}{5}\\
            0 & 0 & 1 & \frac{13}{46}& \frac{-33}{23}\\
            \end{bmatrix} \\ 
            \]
            <br>
            \[
            \xrightarrow{\text{Row2 $\leftrightarrow$ (Row2 + 18/5*Row3)}}
            \begin{bmatrix}
            1 & 0 & 0 & \frac{85}{46} & \frac{131}{23}\\
            0 & 1 & 0 & \frac{51}{23} & \frac{102}{23}\\
            0 & 0 & 1 & \frac{13}{46}& \frac{-33}{23}\\
            \end{bmatrix} \\ 
            \]
            <br>Then we get the solution of the linear system as follows. 
            \[
            \begin{align}
            x_1 &= -\frac{85}{46}x_4 + \frac{131}{23}\\\\
            x_2 &= -\frac{51}{23}x_4 + \frac{102}{23}\\\\
            x_3 &= -\frac{13}{46}x_4 - \frac{33}{23}\\\\
            x_4 & \text{ is a free variable.}
            \end{align}
            \]
            <br> So, in this system we can chooose any value for \(x_4\), which means that any 
            solution of the system is determined by a choice of the free variable \(x_4\). 
        </blockquote>

        <h1>The Matrix Equation</h1>
        <blockquote>
            To get a new point of view toward the system of linear equations, we would like to 
            describe the system with the concept of <strong>vectors</strong>. 
            <br>Given vectors \(v_1, v_2,\cdots, v_p \in \mathbb{R}^n \) and given scalars \(c_1, c_2,\cdots, c_p\),
             the vector \(y\) defined by 
            \[y = c_1v_1 + c_2v_2 + \cdots + c_pv_p\]
            is called a <strong>linear combination</strong> of \(v_1, v_2,\cdots, v_p\) with 
            <strong>weights</strong> \(c_1, c_2,\cdots, c_p\).
            <br><br>Let's take a look back over our matrix 
            \[
            \begin{bmatrix}
            1 & 0 & -3 & 1 & 10\\
            4 & -5 & 6 & -2 & -8\\
            0 & 2 & 2 &  5 & 6\\
            \end{bmatrix}.
            \]
            Let \(a_1 = \begin{bmatrix}
            1 \\
            4 \\
            0 
            \end{bmatrix}, a_2 = \begin{bmatrix}
            0 \\
            -5 \\
            2 
            \end{bmatrix}, a_3 = \begin{bmatrix}
            -3 \\
            6 \\
            2 
            \end{bmatrix},  a_4 = \begin{bmatrix}
            1 \\
            -2 \\
            5 
            \end{bmatrix}\), and \(b =\begin{bmatrix}
            10 \\
            -8 \\
            6 
            \end{bmatrix} \in \mathbb{R}^3\). Notice, \(b\) is generated("spanned") by a linear combination of \(a_1, \cdots, a_4\) because we know
            weights \(x_1, \cdots, x_4\) exist s.t. 
            \[x_1a_1 + x_2a_2 + x_3a_3 + x_4a_4 = b\]
            that is the same solution set we found from our argumented matrix before. 
            Equivalently, we can say a vector <strong>\(b \in Span\{a_1, a_2, a_3, a_4\}\)</strong>, which is 
            the subset of \( \mathbb{R}^3\).
            <br><br>Here, we would like to consider the linear combimation of vectors as the product of a 
            matrix \(A \in \mathbb{R}^{3\times4}\) and a vector \(x\in\mathbb{R}^4\). 
            \[
            Ax = \begin{bmatrix}
            a_1 & a_2 & a_3 & a_4
            \end{bmatrix}\begin{bmatrix}
            x_1 \\
            x_2 \\
            x_3 \\
            x_4 
            \end{bmatrix} = x_1a_1 + x_2a_2 + x_3a_3 + x_4a_4 = b
            \]
            So, we can say that the matrix equation \(Ax = b\) has a solution if and only if \(b\) is a linear combination of 
            the columns of \(A\). 
        </blockquote>

        <h1>Linear Independence</h1>
        <blockquote>
            A set of vectors \(\{v_1, v_2, \cdots, v_p\}\in \mathbb{R}^n \) is called <strong>linearly independent</strong> if
            \[x_1v_1 + x_2v_2 + \cdots + x_pv_p = 0\]
            has "only" the <strong>trivial solution</strong>(the zero vector in \(\mathbb{R}^n\)). 
            <br><br>
            Let's think about a matrix \(A\) instead of the set of vectors. We call \(Ax =0\) the <strong>homogeneous equation</strong>, and
            it always has at least one solution, \(x=0\) aka the trivial solution. So, by the definition of linear independence, we can say
            that \(Ax =0\) has "only" the trivial solution if and only if the columns of \(A\) are linearly independent. 
            <br><br>
            On the other hand, we can say that the homogeneous equation \(Ax =0\) has a <strong>nontrivial solution</strong> if and only if
            the columns of \(A\) are <strong>linearly dependent</strong>. When does this happen? Remember, if a linear system has a free variable,
            basic variables "depend" on a choice of the free variable. In conclusion, the homogeneous equation \(Ax =0\) has a nontrivial solution 
            if and only if the equation has <strong>at least one free variable</strong>, which means the columns of \(A\) are linearly dependent.
        </blockquote>

        <h1>Nonhomogeneous System vs Homogeneous System</h1>
        <blockquote>
            By the way, you might be curious about the relationship between a homogeneous equation
             \(Ax = 0\) and a <strong>nonhomogeneous</strong> equation \(Ax = b\), where \(b\) is a nonzero vector. 
             Yes, there is an important connection between them. Remember, we got the solution of our linear system as follows. 
            \[
            \begin{align}
            x_1 &= -\frac{85}{46}x_4 + \frac{131}{23}\\\\
            x_2 &= -\frac{51}{23}x_4 + \frac{102}{23}\\\\
            x_3 &= -\frac{13}{46}x_4 - \frac{33}{23}\\\\
            x_4 & \text{ is a free variable.}
            \end{align}
            \]
            As a "vector", the <strong>general solution</strong> of \(Ax = b\) can be written as 
            \[
            x = 
            \begin{bmatrix}
            x_1 \\
            x_2 \\
            x_3 \\
            x_4 \\
            \end{bmatrix} 
            = 
            \begin{bmatrix}
            \frac{131}{23}\\
            \frac{102}{23}\\
            - \frac{33}{23}\\
            0
            \end{bmatrix}
            +
            x_4\begin{bmatrix}
            -\frac{85}{46}\\
            -\frac{51}{23} \\
            -\frac{13}{46}\\
            1
            \end{bmatrix}
            = p + x_4v

            \]
            This expression of the set solution is called <strong>parametric vector form</strong>. 
            Now, let's solve the homogeneous system with the same matrix \(A\)
            \[
            \begin{bmatrix}
            1 & 0 & -3 & 1 & 0\\
            4 & -5 & 6 & -2 & 0\\
            0 & 2 & 2 &  5 & 0\\
            \end{bmatrix}
            \xrightarrow{\text{rref}}
            \begin{bmatrix}
            1 & 0 & 0 & \frac{85}{46} & 0\\
            0 & 1 & 0 & \frac{51}{23} & 0\\
            0 & 0 & 1 & \frac{13}{46}&  0\\
            \end{bmatrix} 
            \]
            <br> Then the solution is 
            \[
            \begin{align}
            x_1 &= -\frac{85}{46}x_4 \\\\
            x_2 &= -\frac{51}{23}x_4 \\\\
            x_3 &= -\frac{13}{46}x_4 \\\\
            x_4 & \text{ is a free variable.}
            \end{align}
            \]
            In the parametric vector form, 
            \[x = 
            x_4\begin{bmatrix}
            -\frac{85}{46}\\
            -\frac{51}{23} \\
            -\frac{13}{46}\\
            1
            \end{bmatrix}
            = x_4v
            \]
            This is just the general solution with \(p = 0\). So, the solutions of the nonhomogeneous system 
            \(Ax =b\) are obtained by adding the vector \(p\) to the solution of the homogeneous system \(Ax =0\).
            In addition, we can say that \(p\) is a <strong>particular solution</strong> of \(Ax =b\) with \(x_4 =0\).
            
            \[
            \begin{aligned}
            \textbf{Theorem} \quad 
            & \text{Suppose the system } Ax = b \text{ is consistent for some } b.
            \text{Let } p \text{ be a solution. Then the solution set of } Ax = b \\
            & \text{is the set of all vectors of the form } w = p + v_h 
             \text{where } v_h \text{ is any solution of } Ax = 0.
            \end{aligned}
            \]

        </blockquote>


        <a href="index.html">Back to Home </a>
        <br> <a href="linear_algebra.html">Back to Linear Algebra </a>

    </body>
</html>